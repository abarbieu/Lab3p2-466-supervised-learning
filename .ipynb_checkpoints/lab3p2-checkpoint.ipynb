{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1ce466-51da-481a-b8d5-79ab2e531bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51bedb0d-43ca-4769-8e29-2f09dbad383e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# entropy of a series of data\n",
    "def entropy(classcol):\n",
    "    vals = classcol.value_counts()\n",
    "    size = classcol.count()\n",
    "    entropy=0\n",
    "    for v in vals:\n",
    "        entropy -= (v/size) * math.log(v/size,2)\n",
    "    return entropy\n",
    "\n",
    "# entropy of an attribute in a dataset, over each value of the attribute\n",
    "def entropyAttr(data, attr):\n",
    "    vals = data.pivot(columns=attr,values=data.columns[-1])\n",
    "    entropyTot = 0\n",
    "    for c in vals.columns:\n",
    "        entropyTot += (vals[c].count()/len(data)) * entropy(vals[c])\n",
    "    return entropyTot\n",
    "\n",
    "# entropy of a series of data\n",
    "def entropyValCounts(vals):\n",
    "    size=0\n",
    "    for v in vals:\n",
    "        size += v\n",
    "        \n",
    "    entropy=0\n",
    "    for v in vals:\n",
    "        entropy -= (v/size) * math.log(v/size,2)\n",
    "    return entropy\n",
    "\n",
    "def splitEntropy(le, gt):\n",
    "    sizeLe = 0\n",
    "    for v in le:\n",
    "        sizeLe += v\n",
    "    sizeGt = 0\n",
    "    \n",
    "    for v in gt:\n",
    "        sizeGt += v\n",
    "    \n",
    "    size = sizeLe+sizeGt\n",
    "    \n",
    "    return sizeLe/size * entropyValCounts(le) + sizeGt/size * entropyValCounts(gt)\n",
    "    \n",
    "def calcGainBetter(data,attr,p0):\n",
    "    vals = data[attr].unique()\n",
    "    \n",
    "    bestSplit = None\n",
    "    bestGain = 0.0\n",
    "    for v in vals:\n",
    "        le = data[data[attr] <= v].iloc[:,-1].value_counts()\n",
    "        gt = data[data[attr] > v].iloc[:,-1].value_counts()\n",
    "        \n",
    "        splitGain = p0 - splitEntropy(le,gt)\n",
    "        if splitGain > bestGain:\n",
    "            bestGain = splitGain\n",
    "            bestSplit = v\n",
    "            \n",
    "    return bestSplit, bestGain\n",
    "\n",
    "def findBestSplit(data, attr, p0):\n",
    "    return calcGainBetter(data, attr, p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b656908-5f7e-435b-91ad-d0943936ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSplittingAttr(attrs, data, threshold):\n",
    "    p0 = entropy(data.iloc[:,-1])\n",
    "    bestGain = 0\n",
    "    alpha = None\n",
    "    bestAttr = None\n",
    "    \n",
    "    for a in attrs:\n",
    "        tmpAlpha=None\n",
    "        tmpGain=0\n",
    "        if attrs[a] < 1: # if attr is numeric\n",
    "            tmpAlpha, tmpGain = findBestSplit(data, a, p0)\n",
    "        else:\n",
    "            tmpGain = p0 - entropyAttr(data, a)\n",
    "        if tmpGain > bestGain:\n",
    "            bestAttr = a\n",
    "            bestGain = tmpGain\n",
    "            alpha = tmpAlpha\n",
    "    \n",
    "    if bestGain > threshold:\n",
    "        return bestAttr, alpha\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9417d3a8-33f0-49c0-8597-574bfbdb28f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node': {'var': 'petalLength',\n",
       "  'edges': [{'edge': {'value': 1.9,\n",
       "     'direction': 'le',\n",
       "     'leaf': {'decision': 'Iris-setosa', 'p': 1.0, 'type': 'allsame'}}},\n",
       "   {'edge': {'value': 1.9,\n",
       "     'direction': 'gt',\n",
       "     'node': {'var': 'petalWidth',\n",
       "      'edges': [{'edge': {'value': 1.7,\n",
       "         'direction': 'le',\n",
       "         'node': {'var': 'petalLength',\n",
       "          'edges': [{'edge': {'value': 4.9,\n",
       "             'direction': 'le',\n",
       "             'leaf': {'decision': 'Iris-versicolor',\n",
       "              'p': 0.9791666666666666,\n",
       "              'type': 'threshold'}}},\n",
       "           {'edge': {'value': 4.9,\n",
       "             'direction': 'gt',\n",
       "             'node': {'var': 'petalWidth',\n",
       "              'edges': [{'edge': {'value': 1.5,\n",
       "                 'direction': 'le',\n",
       "                 'leaf': {'decision': 'Iris-virginica',\n",
       "                  'p': 1.0,\n",
       "                  'type': 'allsame'}}},\n",
       "               {'edge': {'value': 1.5,\n",
       "                 'direction': 'gt',\n",
       "                 'node': {'var': 'sepalLength',\n",
       "                  'edges': [{'edge': {'value': '6.7',\n",
       "                     'direction': 'le',\n",
       "                     'leaf': {'decision': 'Iris-versicolor',\n",
       "                      'p': 1.0,\n",
       "                      'type': 'allsame'}}},\n",
       "                   {'edge': {'value': '6.7',\n",
       "                     'direction': 'gt',\n",
       "                     'leaf': {'decision': 'Iris-virginica',\n",
       "                      'p': 1.0,\n",
       "                      'type': 'allsame'}}}]}}}]}}}]}}},\n",
       "       {'edge': {'value': 1.7,\n",
       "         'direction': 'gt',\n",
       "         'leaf': {'decision': 'Iris-virginica',\n",
       "          'p': 0.9782608695652174,\n",
       "          'type': 'threshold'}}}]}}}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class must be in last column\n",
    "def c45(data, attrs, thresh):\n",
    "    # base case 1\n",
    "    classes = data.iloc[:,-1]\n",
    "    firstclass = None\n",
    "    allsame=True\n",
    "    \n",
    "    for c in classes:\n",
    "        if firstclass == None:\n",
    "            firstclass = c\n",
    "        elif c != firstclass:\n",
    "            allsame=False\n",
    "            break\n",
    "            \n",
    "    if allsame:\n",
    "        #create leaf node for perfect purity\n",
    "        return {\"leaf\": {\n",
    "            \"decision\": firstclass,\n",
    "            \"p\": 1.0,\n",
    "            \"type\": \"allsame\"\n",
    "        }}\n",
    "    \n",
    "    pluralityClass = {\n",
    "        \"decision\": classes.mode()[0],\n",
    "        \"p\": classes.value_counts()[classes.mode()][0]/len(classes)\n",
    "    }\n",
    "    \n",
    "    # base case 2\n",
    "    if len(attrs) == 0:\n",
    "        pluralityClass.update({\"type\": \"noAttrs\"})\n",
    "        return {\"leaf\": pluralityClass}                 # create leaf node with most frequent class\n",
    "    \n",
    "    # select splitting attr\n",
    "    asplit, alpha = selectSplittingAttr(attrs, data, thresh)\n",
    "    if asplit is None:\n",
    "        pluralityClass.update({\"type\": \"threshold\"})\n",
    "        return {\"leaf\": pluralityClass}\n",
    "        \n",
    "    elif alpha is None:\n",
    "        attrs.pop(asplit)\n",
    "        newNode = {\"node\": {\"var\": asplit, \"plurality\": pluralityClass, \"edges\": []}}\n",
    "        possibleValues = data[asplit].unique()                # gets unique values in column\n",
    "        \n",
    "        for value in possibleValues:\n",
    "            tic=time.clock()\n",
    "            relatedData = data[(data == value).any(axis = 1)] # take rows that have that value\n",
    "            \n",
    "            if len(relatedData.columns) != 0:\n",
    "                subtree = c45(relatedData, attrs, thresh) \n",
    "                edge = {\"value\": value}\n",
    "                edge.update(subtree)\n",
    "                newNode[\"node\"][\"edges\"].append({\"edge\": edge})\n",
    "        \n",
    "        return newNode\n",
    "    else:\n",
    "        le = data[data[asplit] <= alpha]\n",
    "        gt = data[data[asplit] > alpha]\n",
    "        \n",
    "        leTree = c45(le, attrs, thresh)\n",
    "        gtTree = c45(gt, attrs, thresh)\n",
    "        \n",
    "        leEdge = {\"value\": alpha, \"direction\": \"le\"}\n",
    "        gtEdge = {\"value\": alpha, \"direction\": \"gt\"}\n",
    "        \n",
    "        leEdge.update(leTree)\n",
    "        gtEdge.update(gtTree)\n",
    "        \n",
    "        newNode = {\"node\": {\"var\": asplit, \"edges\": [\n",
    "            {\"edge\": leEdge},\n",
    "            {\"edge\": gtEdge},\n",
    "        ]}}\n",
    "        \n",
    "        return newNode\n",
    "df, filename, tmp, attrs = readFiles(\"./data/iris.data.csv\", )   \n",
    "c45(df,attrs,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8ebbc53-f3cb-4b80-88b8-bf68025c4cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1445fcd28fb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mprintTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minduceC45\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/heart.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-1445fcd28fb0>\u001b[0m in \u001b[0;36minduceC45\u001b[1;34m(trainingData, restrictions, threshold)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadFiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mtree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"dataset\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc45\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-2423c399394e>\u001b[0m in \u001b[0;36mc45\u001b[1;34m(data, attrs, thresh)\u001b[0m\n\u001b[0;32m     23\u001b[0m     pluralityClass = {\n\u001b[0;32m     24\u001b[0m         \u001b[1;34m\"decision\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;34m\"p\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     }\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\numeric.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnan_idxs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Reads a training set csv file and a restrictions vector text file, returns arranged training set          \n",
    "def readFiles(filename=None, restrictions=None):\n",
    "    if filename is None and restrictions is None:\n",
    "        if len(sys.argv) < 2:\n",
    "            print(\"Not enough arguments.\")\n",
    "            exit(1)\n",
    "        elif len(sys.argv) == 3:\n",
    "            restrictions = sys.argv[2]\n",
    "        filename = sys.argv[1]\n",
    "\n",
    "    restr=None\n",
    "    if restrictions != None:\n",
    "        with open(restrictions) as r:\n",
    "            lines = r.read().replace(', ', ' ')\n",
    "            restr = [int(x) for x in lines.split(' ')]\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    aclass = df.iloc[1,0]\n",
    "    \n",
    "    attrs = {}\n",
    "    for a in df.columns:\n",
    "        attrs[a] = int(df[a][0])\n",
    "    \n",
    "    isLabeled = True\n",
    "    if not isinstance(aclass, str):\n",
    "        isLabeled = False\n",
    "    df = df.drop([0,1], axis=0)\n",
    "    if restr != None:\n",
    "        for i,v in enumerate(df.columns):\n",
    "            if restr[i] == 0:\n",
    "                df = df.drop(columns=[v])\n",
    "    if isLabeled:\n",
    "        df = df[[c for c in df if c not in [aclass]] + [aclass]]\n",
    "        \n",
    "    attrs.pop(df.columns[-1])\n",
    "    return df, filename, isLabeled, attrs\n",
    "\n",
    "# runs c45 with data from file of name training data with restrictions in filename restrictions\n",
    "def induceC45(trainingData=None, restrictions=None, threshold=0.2):\n",
    "    df, filename, tmp, attrs = readFiles(trainingData, restrictions)\n",
    "    tree={\"dataset\": filename}\n",
    "    tree.update(c45(df, df.columns[:-1].tolist(), threshold))\n",
    "    return tree\n",
    "\n",
    "\n",
    "# prints a decision tree\n",
    "def printTree(tree):\n",
    "    with open(\"tree.json\", 'w') as f:\n",
    "        json.dump(tree, f)\n",
    "    print(json.dumps(tree, sort_keys=False, indent=2))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    printTree(induceC45(\"./data/heart.csv\", threshold=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
