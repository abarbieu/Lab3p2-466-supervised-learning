{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb1ce466-51da-481a-b8d5-79ab2e531bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "51bedb0d-43ca-4769-8e29-2f09dbad383e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# entropy of a series of data\n",
    "def entropyValCounts(vals):\n",
    "    size=0\n",
    "    for v in vals:\n",
    "        size += v\n",
    "        \n",
    "    entropy=0\n",
    "    for v in vals:\n",
    "        entropy -= (v/size) * math.log(v/size,2)\n",
    "    return entropy\n",
    "\n",
    "def splitEntropy(le, gt):\n",
    "    sizeLe = 0\n",
    "    for v in le:\n",
    "        sizeLe += v\n",
    "    sizeGt = 0\n",
    "    \n",
    "    for v in gt:\n",
    "        sizeGt += v\n",
    "    \n",
    "    size = sizeLe+sizeGt\n",
    "    \n",
    "    return sizeLe/size * entropyValCounts(le) + sizeGt/size * entropyValCounts(gt)\n",
    "    \n",
    "def calcGainBetter(data,attr,p0):\n",
    "    vals = data[attr].unique()\n",
    "    \n",
    "    bestSplit = None\n",
    "    bestGain = 0.0\n",
    "    for v in vals:\n",
    "        le = data[data[attr] <= v].iloc[:,-1].value_counts()\n",
    "        gt = data[data[attr] > v].iloc[:,-1].value_counts()\n",
    "        \n",
    "        splitGain = p0 - splitEntropy(le,gt)\n",
    "        if splitGain > bestGain:\n",
    "            bestGain = splitGain\n",
    "            bestSplit = v\n",
    "            \n",
    "    return bestSplit, bestGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9586d21-5e9d-4d2f-bfb6-36cb5fa89ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestSplit(data, attr, p0):\n",
    "    return calcGainBetter(data, attr, p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9b656908-5f7e-435b-91ad-d0943936ee11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ST_Slope', None)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def selectSplittingAttr(attrs, data, threshold):\n",
    "    p0 = entropy(data.iloc[:,-1])\n",
    "    bestGain = 0\n",
    "    alpha = None\n",
    "    bestAttr = None\n",
    "    \n",
    "    for a in attrs:\n",
    "        tmpAlpha=None\n",
    "        tmpGain=0\n",
    "        if attrs[a] < 1: # if attr is numeric\n",
    "            tmpAlpha, tmpGain = findBestSplit(data, a, p0)\n",
    "        else:\n",
    "            tmpGain = p0 - entropyAttr(data, a)\n",
    "        if tmpGain > bestGain:\n",
    "            bestAttr = a\n",
    "            bestGain = tmpGain\n",
    "            alpha = tmpAlpha\n",
    "    \n",
    "    if bestGain > threshold:\n",
    "        return bestAttr, alpha\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df, filename, tmp, attrs = readFiles(\"./data/heart.csv\")   \n",
    "selectSplittingAttr(attrs, df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "64b33500-f940-4094-8709-8bd52a66c897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age': 0, 'Sex': 2, 'ChestPainType': 4, 'RestingBP': 0, 'Cholesterol': 0, 'FastingBS': 2, 'RestingECG': 3, 'MaxHR': 0, 'ExerciseAngina': 2, 'Oldpeak': 0, 'ST_Slope': 3}\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "# entropy of a series of data\n",
    "def entropy(classcol):\n",
    "    vals = classcol.value_counts()\n",
    "    size = classcol.count()\n",
    "    entropy=0\n",
    "    for v in vals:\n",
    "        entropy -= (v/size) * math.log(v/size,2)\n",
    "    return entropy\n",
    "\n",
    "# entropy of an attribute in a dataset, over each value of the attribute\n",
    "def entropyAttr(data, attr):\n",
    "    vals = data.pivot(columns=attr,values=data.columns[-1])\n",
    "    entropyTot = 0\n",
    "    for c in vals.columns:\n",
    "        entropyTot += (vals[c].count()/len(data)) * entropy(vals[c])\n",
    "    return entropyTot\n",
    "\n",
    "    # class must be in last column\n",
    "def c45(data, attrs, thresh):\n",
    "    # base case 1\n",
    "    #print(data)\n",
    "    classes = data.iloc[:,-1]\n",
    "    firstclass = None\n",
    "    allsame=True\n",
    "    \n",
    "    for c in classes:\n",
    "        if firstclass == None:\n",
    "            firstclass = c\n",
    "        elif c != firstclass:\n",
    "            allsame=False\n",
    "            break\n",
    "            \n",
    "    if allsame:\n",
    "        #create leaf node for perfect purity\n",
    "        return {\"leaf\": {\n",
    "            \"decision\": firstclass,\n",
    "            \"p\": 1.0,\n",
    "            \"type\": \"allsame\"\n",
    "        }}\n",
    "    \n",
    "    pluralityClass = {\n",
    "        \"decision\": classes.mode()[0],\n",
    "        \"p\": classes.value_counts()[classes.mode()][0]/len(classes)\n",
    "    }\n",
    "    \n",
    "    # base case 2\n",
    "    if len(attrs) == 0:\n",
    "        pluralityClass.update({\"type\": \"noAttrs\"})\n",
    "        return {\"leaf\": pluralityClass}                 # create leaf node with most frequent class\n",
    "    \n",
    "    # select splitting attr\n",
    "    asplit = selectSplittingAttr(attrs, data, thresh)\n",
    "    if asplit == None:\n",
    "        pluralityClass.update({\"type\": \"threshold\"})\n",
    "        return {\"leaf\": pluralityClass}\n",
    "        \n",
    "    else:\n",
    "        attrs.pop(asplit)\n",
    "        newNode = {\"node\": {\"var\": asplit, \"plurality\": pluralityClass, \"edges\": []}}\n",
    "        possibleValues = data[asplit].unique()                # gets unique values in column\n",
    "        \n",
    "        for value in possibleValues:\n",
    "            tic=time.clock()\n",
    "            relatedData = data[(data == value).any(axis = 1)] # take rows that have that value\n",
    "            \n",
    "            if len(relatedData.columns) != 0:\n",
    "                subtree = c45(relatedData, attrs, thresh) \n",
    "                edge = {\"value\": value}\n",
    "                edge.update(subtree)\n",
    "                newNode[\"node\"][\"edges\"].append({\"edge\": edge})\n",
    "        return newNode\n",
    "\n",
    "# Reads a training set csv file and a restrictions vector text file, returns arranged training set          \n",
    "def readFiles(filename=None, restrictions=None):\n",
    "    if filename is None and restrictions is None:\n",
    "        if len(sys.argv) < 2:\n",
    "            print(\"Not enough arguments.\")\n",
    "            exit(1)\n",
    "        elif len(sys.argv) == 3:\n",
    "            restrictions = sys.argv[2]\n",
    "        filename = sys.argv[1]\n",
    "\n",
    "    restr=None\n",
    "    if restrictions != None:\n",
    "        with open(restrictions) as r:\n",
    "            lines = r.read().replace(', ', ' ')\n",
    "            restr = [int(x) for x in lines.split(' ')]\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    aclass = df.iloc[1,0]\n",
    "    \n",
    "    attrs = {}\n",
    "    for a in df.columns:\n",
    "        attrs[a] = int(df[a][0])\n",
    "    \n",
    "    isLabeled = True\n",
    "    if not isinstance(aclass, str):\n",
    "        isLabeled = False\n",
    "    df = df.drop([0,1], axis=0)\n",
    "    if restr != None:\n",
    "        for i,v in enumerate(df.columns):\n",
    "            if restr[i] == 0:\n",
    "                df = df.drop(columns=[v])\n",
    "    if isLabeled:\n",
    "        df = df[[c for c in df if c not in [aclass]] + [aclass]]\n",
    "        \n",
    "    attrs.pop(df.columns[-1])\n",
    "    return df, filename, isLabeled, attrs\n",
    "\n",
    "# runs c45 with data from file of name training data with restrictions in filename restrictions\n",
    "def induceC45(trainingData=None, restrictions=None, threshold=0.2):\n",
    "    df,filename,tmp, attrs = readFiles(trainingData, restrictions)\n",
    "    print(attrs)\n",
    "#     tree={\"dataset\": filename}\n",
    "#     tree.update(c45(df, df.columns[:-1].tolist(), threshold))\n",
    "#     return tree\n",
    "\n",
    "\n",
    "# prints a decision tree\n",
    "def printTree(tree):\n",
    "    with open(\"tree.json\", 'w') as f:\n",
    "        json.dump(tree, f)\n",
    "    print(json.dumps(tree, sort_keys=False, indent=2))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    printTree(induceC45(\"./data/heart.csv\", threshold=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
